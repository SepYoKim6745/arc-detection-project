{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5921757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c4e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 정의\n",
    "column_names = ['timestamp', 'v_raw', 'c_raw', 'voltage', 'current', 'label']\n",
    "\n",
    "# 정상 데이터\n",
    "normal_dir = '../realtime/normal/'\n",
    "normal_files = glob.glob(os.path.join(normal_dir, '*.csv'))\n",
    "normal_dfs = [pd.read_csv(file, names=column_names, header=None) for file in normal_files]\n",
    "normal_data = pd.concat(normal_dfs, ignore_index=True)\n",
    "\n",
    "# 아크 데이터\n",
    "arc_dir = '../realtime/arc/'\n",
    "arc_files = glob.glob(os.path.join(arc_dir, '*.csv'))\n",
    "arc_dfs = [pd.read_csv(file, names=column_names, header=None) for file in arc_files]\n",
    "arc_data = pd.concat(arc_dfs, ignore_index=True)\n",
    "\n",
    "# 전체 병합 및 셔플\n",
    "train_df = pd.concat([normal_data, arc_data], ignore_index=True)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d9aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생 피처\n",
    "def add_features(df):\n",
    "    df['voltage_diff'] = df['voltage'].diff().fillna(0).abs()\n",
    "    df['current_diff'] = df['current'].diff().fillna(0).abs()\n",
    "    df['voltage_ma'] = df['voltage'].rolling(5).mean().bfill()\n",
    "    df['current_ma'] = df['current'].rolling(5).mean().bfill()\n",
    "    df['power'] = df['voltage'] * df['current']\n",
    "    df['power_diff'] = df['power'].diff().fillna(0).abs()\n",
    "    return df\n",
    "\n",
    "df = add_features(train_df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735d0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['voltage', 'current', 'voltage_diff', 'current_diff',\n",
    "            'voltage_ma', 'current_ma', 'power', 'power_diff']\n",
    "\n",
    "X_raw = df[features].values\n",
    "y_raw = df['label'].values.astype(int)\n",
    "\n",
    "# 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935e595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 생성\n",
    "def create_sequences(data, labels, seq_len=8):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(labels[i+seq_len - 1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_len = 8\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_raw, seq_len)\n",
    "X_seq = X_seq.reshape((X_seq.shape[0], seq_len, len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "720fc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, stratify=y_seq, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff9d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 16ms/step - accuracy: 0.7551 - loss: 0.5776 - val_accuracy: 0.7690 - val_loss: 0.5221\n",
      "Epoch 2/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.7719 - loss: 0.5342 - val_accuracy: 0.7839 - val_loss: 0.5028\n",
      "Epoch 3/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7875 - loss: 0.5036 - val_accuracy: 0.7891 - val_loss: 0.4960\n",
      "Epoch 4/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7847 - loss: 0.5007 - val_accuracy: 0.7899 - val_loss: 0.4905\n",
      "Epoch 5/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7877 - loss: 0.4990 - val_accuracy: 0.7924 - val_loss: 0.4849\n",
      "Epoch 6/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.7909 - loss: 0.4920 - val_accuracy: 0.7933 - val_loss: 0.4800\n",
      "Epoch 7/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7933 - loss: 0.4900 - val_accuracy: 0.7933 - val_loss: 0.4789\n",
      "Epoch 8/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.7950 - loss: 0.4783 - val_accuracy: 0.7955 - val_loss: 0.4774\n",
      "Epoch 9/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7948 - loss: 0.4818 - val_accuracy: 0.7952 - val_loss: 0.4767\n",
      "Epoch 10/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8005 - loss: 0.4732 - val_accuracy: 0.7965 - val_loss: 0.4757\n",
      "Epoch 11/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8004 - loss: 0.4748 - val_accuracy: 0.7981 - val_loss: 0.4722\n",
      "Epoch 12/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8019 - loss: 0.4737 - val_accuracy: 0.7987 - val_loss: 0.4728\n",
      "Epoch 13/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8030 - loss: 0.4745 - val_accuracy: 0.7979 - val_loss: 0.4715\n",
      "Epoch 14/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8025 - loss: 0.4730 - val_accuracy: 0.8009 - val_loss: 0.4685\n",
      "Epoch 15/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8001 - loss: 0.4721 - val_accuracy: 0.8019 - val_loss: 0.4700\n",
      "Epoch 16/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7974 - loss: 0.4754 - val_accuracy: 0.8019 - val_loss: 0.4671\n",
      "Epoch 17/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8005 - loss: 0.4711 - val_accuracy: 0.8022 - val_loss: 0.4692\n",
      "Epoch 18/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8033 - loss: 0.4710 - val_accuracy: 0.8046 - val_loss: 0.4655\n",
      "Epoch 19/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8027 - loss: 0.4717 - val_accuracy: 0.8020 - val_loss: 0.4660\n",
      "Epoch 20/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.7998 - loss: 0.4760 - val_accuracy: 0.8019 - val_loss: 0.4671\n",
      "Epoch 21/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8067 - loss: 0.4619 - val_accuracy: 0.8029 - val_loss: 0.4679\n",
      "Epoch 22/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8048 - loss: 0.4645 - val_accuracy: 0.8023 - val_loss: 0.4658\n",
      "Epoch 23/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8047 - loss: 0.4671 - val_accuracy: 0.8036 - val_loss: 0.4639\n",
      "Epoch 24/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8048 - loss: 0.4632 - val_accuracy: 0.8036 - val_loss: 0.4646\n",
      "Epoch 25/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8014 - loss: 0.4699 - val_accuracy: 0.8053 - val_loss: 0.4711\n",
      "Epoch 26/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8070 - loss: 0.4648 - val_accuracy: 0.8011 - val_loss: 0.4701\n",
      "Epoch 27/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8048 - loss: 0.4626 - val_accuracy: 0.8077 - val_loss: 0.4640\n",
      "Epoch 28/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8038 - loss: 0.4696 - val_accuracy: 0.8058 - val_loss: 0.4631\n",
      "Epoch 29/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8093 - loss: 0.4601 - val_accuracy: 0.8069 - val_loss: 0.4652\n",
      "Epoch 30/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8091 - loss: 0.4565 - val_accuracy: 0.8048 - val_loss: 0.4692\n",
      "Epoch 31/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8052 - loss: 0.4670 - val_accuracy: 0.8062 - val_loss: 0.4765\n",
      "Epoch 32/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8057 - loss: 0.4663 - val_accuracy: 0.8059 - val_loss: 0.4647\n",
      "Epoch 33/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8088 - loss: 0.4605 - val_accuracy: 0.8080 - val_loss: 0.4672\n",
      "Epoch 34/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8030 - loss: 0.4672 - val_accuracy: 0.8039 - val_loss: 0.4742\n",
      "Epoch 35/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8063 - loss: 0.4615 - val_accuracy: 0.8086 - val_loss: 0.4683\n",
      "Epoch 36/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8049 - loss: 0.4627 - val_accuracy: 0.8070 - val_loss: 0.4627\n",
      "Epoch 37/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8081 - loss: 0.4579 - val_accuracy: 0.8068 - val_loss: 0.4620\n",
      "Epoch 38/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8012 - loss: 0.4711 - val_accuracy: 0.8088 - val_loss: 0.4636\n",
      "Epoch 39/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8080 - loss: 0.4618 - val_accuracy: 0.8062 - val_loss: 0.4686\n",
      "Epoch 40/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8093 - loss: 0.4589 - val_accuracy: 0.8074 - val_loss: 0.4625\n",
      "Epoch 41/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8058 - loss: 0.4586 - val_accuracy: 0.8083 - val_loss: 0.4732\n",
      "Epoch 42/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8087 - loss: 0.4627 - val_accuracy: 0.8073 - val_loss: 0.4772\n",
      "Epoch 43/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8083 - loss: 0.4604 - val_accuracy: 0.8084 - val_loss: 0.4648\n",
      "Epoch 44/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8097 - loss: 0.4546 - val_accuracy: 0.8070 - val_loss: 0.4657\n",
      "Epoch 45/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8082 - loss: 0.4598 - val_accuracy: 0.8086 - val_loss: 0.4610\n",
      "Epoch 46/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8101 - loss: 0.4560 - val_accuracy: 0.8064 - val_loss: 0.4636\n",
      "Epoch 47/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8117 - loss: 0.4557 - val_accuracy: 0.8036 - val_loss: 0.4673\n",
      "Epoch 48/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8083 - loss: 0.4598 - val_accuracy: 0.8068 - val_loss: 0.4628\n",
      "Epoch 49/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8109 - loss: 0.4598 - val_accuracy: 0.8011 - val_loss: 0.4840\n",
      "Epoch 50/50\n",
      "\u001b[1m512/512\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.8025 - loss: 0.4690 - val_accuracy: 0.8063 - val_loss: 0.4750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x34c0b77f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(seq_len, len(features)))\n",
    "x = Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f74fee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/scaler_cnn.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 및 스케일러 저장\n",
    "model.save('./model/cnn1d_model.h5')\n",
    "joblib.dump(scaler, './model/scaler_cnn.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f713c951",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./model/cnn1d_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m converter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mTFLiteConverter\u001b[38;5;241m.\u001b[39mfrom_keras_model(model)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('./model/cnn1d_model.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# 핵심 설정: 구버전 연산자만 사용하도록 제한\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]  \n",
    "\n",
    "# (선택) float16 경량화도 가능\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"./model/cnn1d_model_compatible.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
