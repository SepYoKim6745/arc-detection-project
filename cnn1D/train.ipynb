{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5921757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 임포트\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65c4e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 정의\n",
    "column_names = ['timestamp', 'v_raw', 'c_raw', 'voltage', 'current', 'label']\n",
    "\n",
    "# 정상 데이터\n",
    "normal_dir = '../realtime/normal/'\n",
    "normal_files = glob.glob(os.path.join(normal_dir, '*.csv'))\n",
    "normal_dfs = [pd.read_csv(file, names=column_names, header=None) for file in normal_files]\n",
    "normal_data = pd.concat(normal_dfs, ignore_index=True)\n",
    "\n",
    "# 아크 데이터\n",
    "arc_dir = '../realtime/arc/'\n",
    "arc_files = glob.glob(os.path.join(arc_dir, '*.csv'))\n",
    "arc_dfs = [pd.read_csv(file, names=column_names, header=None) for file in arc_files]\n",
    "arc_data = pd.concat(arc_dfs, ignore_index=True)\n",
    "\n",
    "# 전체 병합 및 셔플\n",
    "train_df = pd.concat([normal_data, arc_data], ignore_index=True)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d9aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생 피처\n",
    "def add_features(df):\n",
    "    df['voltage_diff'] = df['voltage'].diff().fillna(0).abs()\n",
    "    df['current_diff'] = df['current'].diff().fillna(0).abs()\n",
    "    df['voltage_ma'] = df['voltage'].rolling(5).mean().bfill()\n",
    "    df['current_ma'] = df['current'].rolling(5).mean().bfill()\n",
    "    df['power'] = df['voltage'] * df['current']\n",
    "    df['power_diff'] = df['power'].diff().fillna(0).abs()\n",
    "    return df\n",
    "\n",
    "train_df = add_features(train_df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "735d0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우로 시퀀스 생성\n",
    "def create_sequences(data, labels, seq_len=8):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(labels[i+seq_len - 1])  # 마지막 시점의 label 사용\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "features = ['voltage', 'current', 'voltage_diff', 'current_diff',\n",
    "            'voltage_ma', 'current_ma', 'power', 'power_diff']\n",
    "X_raw = train_df[features].values\n",
    "y_raw = train_df['label'].values.astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "seq_len = 8\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_raw, seq_len=seq_len)\n",
    "\n",
    "# CNN 입력 형태로 reshape: (samples, timesteps, features)\n",
    "X_seq = X_seq.reshape((X_seq.shape[0], seq_len, len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "720fc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ff9d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NGN Lab\\Desktop\\kys\\논문\\전기안전공학\\source\\arc-detection-project\\powerenv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 모델 정의\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=(seq_len, len(features))),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74fee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8724 - loss: 0.3852 - val_accuracy: 0.8856 - val_loss: 0.3481\n",
      "Epoch 2/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.3557 - val_accuracy: 0.8856 - val_loss: 0.3408\n",
      "Epoch 3/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8868 - loss: 0.3418 - val_accuracy: 0.8856 - val_loss: 0.3350\n",
      "Epoch 4/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8877 - loss: 0.3319 - val_accuracy: 0.8854 - val_loss: 0.3297\n",
      "Epoch 5/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8879 - loss: 0.3243 - val_accuracy: 0.8899 - val_loss: 0.3154\n",
      "Epoch 6/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.8942 - loss: 0.3130 - val_accuracy: 0.8960 - val_loss: 0.3105\n",
      "Epoch 7/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8916 - loss: 0.3201 - val_accuracy: 0.9000 - val_loss: 0.3046\n",
      "Epoch 8/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8947 - loss: 0.3089 - val_accuracy: 0.8980 - val_loss: 0.3067\n",
      "Epoch 9/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 0.3030 - val_accuracy: 0.8996 - val_loss: 0.3038\n",
      "Epoch 10/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9009 - loss: 0.2999 - val_accuracy: 0.9027 - val_loss: 0.3019\n",
      "Epoch 11/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9027 - loss: 0.2946 - val_accuracy: 0.9033 - val_loss: 0.3000\n",
      "Epoch 12/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.2933 - val_accuracy: 0.9037 - val_loss: 0.3012\n",
      "Epoch 13/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9006 - loss: 0.2958 - val_accuracy: 0.9027 - val_loss: 0.2994\n",
      "Epoch 14/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.2891 - val_accuracy: 0.9043 - val_loss: 0.3049\n",
      "Epoch 15/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9076 - loss: 0.2822 - val_accuracy: 0.9029 - val_loss: 0.2991\n",
      "Epoch 16/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9036 - loss: 0.2941 - val_accuracy: 0.9041 - val_loss: 0.2979\n",
      "Epoch 17/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9088 - loss: 0.2750 - val_accuracy: 0.9041 - val_loss: 0.2959\n",
      "Epoch 18/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9092 - loss: 0.2756 - val_accuracy: 0.9055 - val_loss: 0.2943\n",
      "Epoch 19/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2769 - val_accuracy: 0.9071 - val_loss: 0.3021\n",
      "Epoch 20/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2732 - val_accuracy: 0.9051 - val_loss: 0.2974\n",
      "Epoch 21/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.2805 - val_accuracy: 0.9037 - val_loss: 0.3004\n",
      "Epoch 22/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9145 - loss: 0.2632 - val_accuracy: 0.9075 - val_loss: 0.2959\n",
      "Epoch 23/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.2719 - val_accuracy: 0.9065 - val_loss: 0.2946\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f713c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/scaler_cnn.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 저장\n",
    "model.save('./model/cnn1d_model.h5')\n",
    "joblib.dump(scaler, './model/scaler_cnn.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "042df562",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmp7gh5ndzu\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmp7gh5ndzu\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmp7gh5ndzu'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 8, 8), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1927348353936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927349771664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927349769936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927349771280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927349770320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927349771088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927349770512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1927349772816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "✅ TFLite 변환 및 경량화 완료!\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# TFLite 경량화 및 저장\n",
    "import tensorflow as tf\n",
    "\n",
    "# GPU 관련 충돌 방지 (필수 아님, 하지만 권장)\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "# 모델 로드\n",
    "model = tf.keras.models.load_model('./model/cnn1d_model.h5')\n",
    "\n",
    "# 변환기 설정\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]  # 기본 최적화 (dynamic range quantization)\n",
    "\n",
    "# 만약 float16 quantization도 시도하고 싶다면 아래 주석을 해제하세요:\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "# 변환 수행\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# 저장\n",
    "with open('./model/cnn1d_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "print(\"✅ TFLite 변환 및 경량화 완료!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "powerenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
