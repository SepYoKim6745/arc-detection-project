{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5921757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65c4e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컬럼명 정의\n",
    "column_names = ['timestamp', 'v_raw', 'c_raw', 'voltage', 'current', 'label']\n",
    "\n",
    "# # 정상 데이터\n",
    "# normal_dir = '../realtime/normal/'\n",
    "# normal_files = glob.glob(os.path.join(normal_dir, '*.csv'))\n",
    "# normal_dfs = [pd.read_csv(file, names=column_names, header=None) for file in normal_files]\n",
    "# normal_data = pd.concat(normal_dfs, ignore_index=True)\n",
    "\n",
    "# # 아크 데이터\n",
    "# arc_dir = '../realtime/arc/'\n",
    "# arc_files = glob.glob(os.path.join(arc_dir, '*.csv'))\n",
    "# arc_dfs = [pd.read_csv(file, names=column_names, header=None) for file in arc_files]\n",
    "# arc_data = pd.concat(arc_dfs, ignore_index=True)\n",
    "\n",
    "# # 전체 병합 및 셔플\n",
    "# train_df = pd.concat([normal_data, arc_data], ignore_index=True)\n",
    "# train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "train_df = pd.read_csv('./log/0529/학습데이터/통합 데이터(45초).csv', names=column_names, header=None)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64d9aa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파생 피처\n",
    "def add_features(df):\n",
    "    df['voltage_diff'] = df['voltage'].diff().fillna(0).abs()\n",
    "    df['current_diff'] = df['current'].diff().fillna(0).abs()\n",
    "    df['voltage_ma'] = df['voltage'].rolling(5).mean().bfill()\n",
    "    df['current_ma'] = df['current'].rolling(5).mean().bfill()\n",
    "    df['power'] = df['voltage'] * df['current']\n",
    "    df['power_diff'] = df['power'].diff().fillna(0).abs()\n",
    "    return df\n",
    "\n",
    "df = add_features(train_df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "735d0caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['voltage', 'current', 'voltage_diff', 'current_diff',\n",
    "            'voltage_ma', 'current_ma', 'power', 'power_diff']\n",
    "\n",
    "X_raw = df[features].values\n",
    "y_raw = df['label'].values.astype(int)\n",
    "\n",
    "# 정규화\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935e595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시퀀스 생성\n",
    "def create_sequences(data, labels, seq_len=8):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(labels[i+seq_len - 1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_len = 8\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_raw, seq_len)\n",
    "X_seq = X_seq.reshape((X_seq.shape[0], seq_len, len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "720fc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습/검증 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=None, stratify=y_seq, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ff9d605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.7665 - loss: 0.5262 - val_accuracy: 0.8661 - val_loss: 0.4062\n",
      "Epoch 2/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8646 - loss: 0.4212 - val_accuracy: 0.8661 - val_loss: 0.4010\n",
      "Epoch 3/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8666 - loss: 0.4135 - val_accuracy: 0.8661 - val_loss: 0.4058\n",
      "Epoch 4/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8510 - loss: 0.4281 - val_accuracy: 0.8661 - val_loss: 0.4067\n",
      "Epoch 5/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8723 - loss: 0.3791 - val_accuracy: 0.8661 - val_loss: 0.4139\n",
      "Epoch 6/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8722 - loss: 0.3756 - val_accuracy: 0.8661 - val_loss: 0.4111\n",
      "Epoch 7/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8666 - loss: 0.3825 - val_accuracy: 0.8661 - val_loss: 0.4060\n",
      "Epoch 8/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8608 - loss: 0.3882 - val_accuracy: 0.8661 - val_loss: 0.4075\n",
      "Epoch 9/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8636 - loss: 0.3740 - val_accuracy: 0.8661 - val_loss: 0.4082\n",
      "Epoch 10/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8635 - loss: 0.3702 - val_accuracy: 0.8661 - val_loss: 0.4164\n",
      "Epoch 11/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8693 - loss: 0.3610 - val_accuracy: 0.8661 - val_loss: 0.4142\n",
      "Epoch 12/50\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8663 - loss: 0.3561 - val_accuracy: 0.8661 - val_loss: 0.4176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1d71a2cdd50>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = Input(shape=(seq_len, len(features)))\n",
    "x = Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D(2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "early_stop = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=50, batch_size=64, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74fee42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/scaler_cnn_new.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 및 스케일러 저장\n",
    "model.save('./model/cnn1d_model_new.h5')\n",
    "joblib.dump(scaler, './model/scaler_cnn_new.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f713c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmpx4x8fit3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmpx4x8fit3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmpx4x8fit3'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 8, 8), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2023476598160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2023476603088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2023466994144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2023476609792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2023476613664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2023476610848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2023476615952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2023476613840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('./model/cnn1d_model_new.h5')\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# 핵심 설정: 구버전 연산자만 사용하도록 제한\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]  \n",
    "\n",
    "# (선택) float16 경량화도 가능\n",
    "# converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.target_spec.supported_types = [tf.float16]\n",
    "\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"./model/cnn1d_model_compatible_new.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "power-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
