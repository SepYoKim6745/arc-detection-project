{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "865e867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import time\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a67510e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»¬ëŸ¼ëª… ì •ì˜\n",
    "column_names = ['timestamp', 'v_raw', 'c_raw', 'voltage', 'current', 'label']\n",
    "\n",
    "# ì •ìƒ ë°ì´í„°\n",
    "normal_dir = '../realtime/normal/'\n",
    "normal_files = glob.glob(os.path.join(normal_dir, '*.csv'))\n",
    "normal_dfs = [pd.read_csv(file, names=column_names, header=None) for file in normal_files]\n",
    "normal_data = pd.concat(normal_dfs, ignore_index=True)\n",
    "\n",
    "# ì•„í¬ ë°ì´í„°\n",
    "arc_dir = '../realtime/arc/'\n",
    "arc_files = glob.glob(os.path.join(arc_dir, '*.csv'))\n",
    "arc_dfs = [pd.read_csv(file, names=column_names, header=None) for file in arc_files]\n",
    "arc_data = pd.concat(arc_dfs, ignore_index=True)\n",
    "\n",
    "# ì „ì²´ ë³‘í•© ë° ì…”í”Œ\n",
    "train_df = pd.concat([normal_data, arc_data], ignore_index=True)\n",
    "train_df = train_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc1cbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒìƒ í”¼ì²˜\n",
    "def add_features(df):\n",
    "    df['voltage_diff'] = df['voltage'].diff().fillna(0).abs()\n",
    "    df['current_diff'] = df['current'].diff().fillna(0).abs()\n",
    "    df['voltage_ma'] = df['voltage'].rolling(5).mean().bfill()\n",
    "    df['current_ma'] = df['current'].rolling(5).mean().bfill()\n",
    "    df['power'] = df['voltage'] * df['current']\n",
    "    df['power_diff'] = df['power'].diff().fillna(0).abs()\n",
    "    return df\n",
    "\n",
    "train_df = add_features(train_df).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ebf7ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¬ë¼ì´ë”© ìœˆë„ìš°ë¡œ ì‹œí€€ìŠ¤ ìƒì„±\n",
    "def create_sequences(data, labels, seq_len=8):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_len):\n",
    "        X.append(data[i:i+seq_len])\n",
    "        y.append(labels[i+seq_len - 1])  # ë§ˆì§€ë§‰ ì‹œì ì˜ label ì‚¬ìš©\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "features = ['voltage', 'current', 'voltage_diff', 'current_diff',\n",
    "            'voltage_ma', 'current_ma', 'power', 'power_diff']\n",
    "X_raw = train_df[features].values\n",
    "y_raw = train_df['label'].values.astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_raw)\n",
    "\n",
    "seq_len = 8\n",
    "X_seq, y_seq = create_sequences(X_scaled, y_raw, seq_len=seq_len)\n",
    "\n",
    "# CNN ì…ë ¥ í˜•íƒœë¡œ reshape: (samples, timesteps, features)\n",
    "X_seq = X_seq.reshape((X_seq.shape[0], seq_len, len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eae65142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ/ê²€ì¦ ë¶„í• \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, stratify=y_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "222c52c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/arcenv/lib/python3.9/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# ëª¨ë¸ ì •ì˜\n",
    "model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', padding='same', input_shape=(seq_len, len(features))),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Dropout(0.3),\n",
    "    Conv1D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d59c345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 19:51:34.398144: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 16ms/step - accuracy: 0.8773 - loss: 0.3950 - val_accuracy: 0.8854 - val_loss: 0.3480\n",
      "Epoch 2/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8874 - loss: 0.3584 - val_accuracy: 0.8854 - val_loss: 0.3370\n",
      "Epoch 3/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8848 - loss: 0.3477 - val_accuracy: 0.8867 - val_loss: 0.3414\n",
      "Epoch 4/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8834 - loss: 0.3440 - val_accuracy: 0.8879 - val_loss: 0.3243\n",
      "Epoch 5/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8883 - loss: 0.3375 - val_accuracy: 0.8909 - val_loss: 0.3155\n",
      "Epoch 6/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8874 - loss: 0.3284 - val_accuracy: 0.8982 - val_loss: 0.3089\n",
      "Epoch 7/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8971 - loss: 0.3092 - val_accuracy: 0.8968 - val_loss: 0.3057\n",
      "Epoch 8/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8958 - loss: 0.3140 - val_accuracy: 0.8962 - val_loss: 0.3045\n",
      "Epoch 9/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.8982 - loss: 0.3118 - val_accuracy: 0.9004 - val_loss: 0.2993\n",
      "Epoch 10/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9025 - loss: 0.2999 - val_accuracy: 0.9010 - val_loss: 0.2990\n",
      "Epoch 11/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9013 - loss: 0.2996 - val_accuracy: 0.9014 - val_loss: 0.2970\n",
      "Epoch 12/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9046 - loss: 0.2953 - val_accuracy: 0.9020 - val_loss: 0.2967\n",
      "Epoch 13/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9024 - loss: 0.2969 - val_accuracy: 0.9037 - val_loss: 0.2923\n",
      "Epoch 14/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9026 - loss: 0.2945 - val_accuracy: 0.9067 - val_loss: 0.2904\n",
      "Epoch 15/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9062 - loss: 0.2877 - val_accuracy: 0.9075 - val_loss: 0.2868\n",
      "Epoch 16/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9010 - loss: 0.2908 - val_accuracy: 0.9063 - val_loss: 0.2879\n",
      "Epoch 17/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9052 - loss: 0.2831 - val_accuracy: 0.9069 - val_loss: 0.2901\n",
      "Epoch 18/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9064 - loss: 0.2838 - val_accuracy: 0.9069 - val_loss: 0.2959\n",
      "Epoch 19/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9066 - loss: 0.2816 - val_accuracy: 0.9083 - val_loss: 0.2880\n",
      "Epoch 20/50\n",
      "\u001b[1m317/317\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9097 - loss: 0.2787 - val_accuracy: 0.9079 - val_loss: 0.2890\n"
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ\n",
    "early_stop = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92bc6621",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/scaler_cnn.joblib']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì €ì¥\n",
    "model.save('./model/cnn1d_model.h5')\n",
    "joblib.dump(scaler, './model/scaler_cnn.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf816e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmphywsotu0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmphywsotu0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\NGNLAB~1\\AppData\\Local\\Temp\\tmphywsotu0'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 8, 8), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  1971097574224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1971097575376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1971097574992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1971097573264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1971097575760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1971097575952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1971097577104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  1971097578064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# ê¸°ì¡´ .h5 ëª¨ë¸ ë¡œë“œ\n",
    "model = tf.keras.models.load_model('./model/cnn1d_model.h5')\n",
    "\n",
    "# TFLite ë³€í™˜ê¸° ì„¤ì •\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# .tflite ëª¨ë¸ ì €ì¥\n",
    "with open(\"./model/cnn1d_model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32103668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob.flatten() > 0.0555).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd6ee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_anomalies(y_pred_bin, min_consecutive=8):\n",
    "    y_post = np.zeros_like(y_pred_bin)\n",
    "    count = 0\n",
    "    for i, val in enumerate(y_pred_bin):\n",
    "        if val == 1:\n",
    "            count += 1\n",
    "        else:\n",
    "            if count >= min_consecutive:\n",
    "                y_post[i - count:i] = 1\n",
    "            count = 0\n",
    "    if count >= min_consecutive:\n",
    "        y_post[len(y_pred_bin)-count:] = 1\n",
    "    return y_post\n",
    "\n",
    "y_pred_post = postprocess_anomalies(y_pred, min_consecutive=8)\n",
    "y_true_post = postprocess_anomalies(y_test, min_consecutive=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c032046",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“‹ (í›„ì²˜ë¦¬ ì ìš©) ë¶„ë¥˜ ë¦¬í¬íŠ¸:\\n\")\n",
    "print(classification_report(y_true_post, y_pred_post, target_names=['ì •ìƒ', 'ì•„í¬']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detection_delay(y_pred_bin, label, sampling_interval=0.0001):\n",
    "    arc_start = np.where(label == 1)[0][0]\n",
    "    detected = np.where(y_pred_bin[arc_start:] == 1)[0]\n",
    "    if len(detected) == 0:\n",
    "        print(\"âš ï¸ ì•„í¬ë¥¼ íƒì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "    detect_index = detected[0] + arc_start\n",
    "    delay = detect_index - arc_start\n",
    "    time_detected = detect_index * sampling_interval\n",
    "    print(f\"âœ… ì•„í¬ ì‹œì‘ ì¸ë±ìŠ¤: {arc_start}\")\n",
    "    print(f\"âœ… ëª¨ë¸ ì´ìƒ ê°ì§€ ì¸ë±ìŠ¤: {detect_index}\")\n",
    "    print(f\"â±ï¸ ê°ì§€ ì§€ì—° ì‹œê°„: {delay} ìƒ˜í”Œ\")\n",
    "    print(f\"â±ï¸ ê°ì§€ëœ ì‹œì  (ì´ˆ): {time_detected:.6f} ì´ˆ\")\n",
    "    return arc_start, detect_index, delay\n",
    "\n",
    "arc_start, detect_index, delay = calculate_detection_delay(y_pred_post, y_true_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080e85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ì˜ˆì¸¡ ì‹œê°„\n",
    "start_total = time.perf_counter()\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_prob.flatten() > 0.5).astype(int)\n",
    "elapsed_total = time.perf_counter() - start_total\n",
    "print(f\"â±ï¸ ì „ì²´ ì˜ˆì¸¡ ì†Œìš” ì‹œê°„: {elapsed_total:.10f}ì´ˆ\")\n",
    "\n",
    "# í›„ì²˜ë¦¬ + ì²« ì´ìƒ ê°ì§€ê¹Œì§€ ì‹œê°„\n",
    "start_first = time.perf_counter()\n",
    "y_pred_post = postprocess_anomalies(y_pred, min_consecutive=8)\n",
    "first_index = np.where(y_pred_post == 1)[0]\n",
    "elapsed_first = time.perf_counter() - start_first\n",
    "\n",
    "if len(first_index) > 0:\n",
    "    print(f\"ğŸŸ¡ ì²« ë²ˆì§¸ ì´ìƒ íƒì§€ ì¸ë±ìŠ¤: {first_index[0]}\")\n",
    "    print(f\"â±ï¸ ì²« ì´ìƒ íƒì§€ê¹Œì§€ ê±¸ë¦° ì‹œê°„: {elapsed_first:.10f}ì´ˆ\")\n",
    "else:\n",
    "    print(\"âš ï¸ í›„ì²˜ë¦¬ëœ ì´ìƒ íƒì§€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4c720c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë“ˆ ì„í¬íŠ¸\n",
    "import psutil\n",
    "import os\n",
    "\n",
    "# ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¶œë ¥ í•¨ìˆ˜\n",
    "def print_resource_usage():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    mem_info = process.memory_info()\n",
    "    cpu_percent = process.cpu_percent(interval=1.0)\n",
    "    print(f\"ğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {mem_info.rss / 1024 ** 2:.2f} MB\")\n",
    "    print(f\"ğŸ§® CPU ì‚¬ìš©ë¥ : {cpu_percent:.2f}%\")\n",
    "\n",
    "\n",
    "# ì „ì²´ ì˜ˆì¸¡ ì‹œê°„ ì¸¡ì • + ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ì¶œë ¥\n",
    "print(\"ğŸ” ì˜ˆì¸¡ ì „ ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
    "print_resource_usage()\n",
    "\n",
    "start_total = time.perf_counter()\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "elapsed_total = time.perf_counter() - start_total\n",
    "\n",
    "print(\"ğŸ” ì˜ˆì¸¡ í›„ ì‹œìŠ¤í…œ ìƒíƒœ:\")\n",
    "print_resource_usage()\n",
    "\n",
    "print(f\"â±ï¸ ì „ì²´ ì˜ˆì¸¡ ì†Œìš” ì‹œê°„: {elapsed_total:.10f}ì´ˆ\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597ab985",
   "metadata": {},
   "source": [
    "---\n",
    "# ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a13482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì • (ì˜ˆ: ë§‘ì€ ê³ ë”•)\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'  # Windows ì‚¬ìš©ì\n",
    "# plt.rcParams['font.family'] = 'AppleGothic'   # macOS ì‚¬ìš©ì\n",
    "# plt.rcParams['font.family'] = 'NanumGothic'   # Linux ì‚¬ìš©ì (Nanum í°íŠ¸ ì„¤ì¹˜ í•„ìš”)\n",
    "\n",
    "# ë§ˆì´ë„ˆìŠ¤ ë¶€í˜¸ ê¹¨ì§ ë°©ì§€\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252048c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_pred_bin, arc_start=None, detect_index=None):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(y_pred_bin, label='ì˜ˆì¸¡ ì´ìƒ (1=ì´ìƒ)', color='red', linewidth=1)\n",
    "\n",
    "    if arc_start is not None:\n",
    "        plt.axvline(x=arc_start, color='blue', linestyle='--', label='ì‹¤ì œ ì•„í¬ ì‹œì‘')\n",
    "    if detect_index is not None:\n",
    "        plt.axvline(x=detect_index, color='green', linestyle='--', label='ê°ì§€ëœ ì‹œì ')\n",
    "\n",
    "    plt.title(\"CNN ì´ìƒ íƒì§€ ê²°ê³¼\")\n",
    "    plt.xlabel(\"ìƒ˜í”Œ ì¸ë±ìŠ¤\")\n",
    "    plt.ylabel(\"ì˜ˆì¸¡ê°’\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_predictions(y_pred_post, arc_start, detect_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da97d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_current_waveform(test_df):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(test_df['current'], label='ì „ë¥˜ íŒŒí˜•', alpha=0.7)\n",
    "    plt.title(\"ì „ì²´ ì „ë¥˜ íŒŒí˜•\")\n",
    "    plt.xlabel(\"ìƒ˜í”Œ ì¸ë±ìŠ¤\")\n",
    "    plt.ylabel(\"ì „ë¥˜ (A)\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_current_waveform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a33c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_postprocessing(y_pred_bin, y_pred_post, title=\"í›„ì²˜ë¦¬ ì „í›„ ë¹„êµ\"):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(y_pred_bin, label='í›„ì²˜ë¦¬ ì „', color='orange', alpha=0.6)\n",
    "    plt.plot(y_pred_post, label='í›„ì²˜ë¦¬ í›„', color='green', alpha=0.6)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"ìƒ˜í”Œ ì¸ë±ìŠ¤\")\n",
    "    plt.ylabel(\"ì´ìƒ íƒì§€ ê²°ê³¼\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_postprocessing(y_pred, y_pred_post)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ad4b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_prediction_vs_label(y_true, y_pred_post):\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    plt.plot(y_true, label='ì‹¤ì œ ë¼ë²¨', alpha=0.5)\n",
    "    plt.plot(y_pred_post, label='ëª¨ë¸ ì˜ˆì¸¡', alpha=0.7)\n",
    "    plt.title(\"ì‹¤ì œ ë¼ë²¨ vs ëª¨ë¸ ì˜ˆì¸¡ ë¹„êµ\")\n",
    "    plt.xlabel(\"ìƒ˜í”Œ ì¸ë±ìŠ¤\")\n",
    "    plt.ylabel(\"ê°’ (0=ì •ìƒ, 1=ì•„í¬)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "compare_prediction_vs_label(y_true_post, y_pred_post)\n",
    "\n",
    "# # ì°¨ì´ì  ìœ„ì¹˜ ì°¾ê¸°\n",
    "# mismatch_indices = np.where(y_true_post != y_pred_post)[0]\n",
    "# print(\"ë¶ˆì¼ì¹˜ ì¸ë±ìŠ¤:\", mismatch_indices)\n",
    "# print(\"ë¶ˆì¼ì¹˜ ê°œìˆ˜:\", len(mismatch_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e769514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "powerenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
